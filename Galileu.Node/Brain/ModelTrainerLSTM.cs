using System;
using System.Diagnostics;
using System.IO;
using System.Linq;
using System.Collections.Generic; // Necess√°rio para List<>
using Galileu.Node.Core;
using Galileu.Node.Interfaces;
using Galileu.Node.Services;

namespace Galileu.Node.Brain;

/// <summary>
/// Orquestra o treinamento de uma √∫nica √©poca. VERS√ÉO FINAL: Opera diretamente
/// sobre listas de amostras em mem√≥ria, eliminando a depend√™ncia do DatasetService.
/// </summary>
public class ModelTrainerLSTM
{
    private readonly IMathEngine _mathEngine;
    private readonly Stopwatch _stopwatch = new Stopwatch();
    private readonly Process _currentProcess;
    private readonly string logPath = Path.Combine(Environment.CurrentDirectory, "Dayson", "training_log.txt");

    public ModelTrainerLSTM(IMathEngine mathEngine)
    {
        _mathEngine = mathEngine ?? throw new ArgumentNullException(nameof(mathEngine));
        _currentProcess = Process.GetCurrentProcess();
    }

    /// <summary>
    /// üî• CORRE√á√ÉO DEFINITIVA: Executa o treinamento e valida√ß√£o para uma √∫nica √©poca
    /// usando listas de amostras pr√©-processadas em mem√≥ria.
    /// </summary>
    public void TrainSingleEpoch(
        GenerativeNeuralNetworkLSTM model,
        List<(int InputIndex, int TargetIndex)> trainingSamples,
        List<(int InputIndex, int TargetIndex)> validationSamples,
        double learningRate,
        int batchSize)
    {
        _stopwatch.Restart();
        Console.WriteLine($"\n{'‚ïê',60}");
        Console.WriteLine($"INICIANDO √âPOCA DE TREINAMENTO (SFT) >> LR: {learningRate} >> {DateTime.UtcNow}");
        Console.WriteLine($"{'‚ïê',60}");

        double totalEpochLoss = 0;
        int batchCount = 0;
        
        if (trainingSamples.Count == 0)
        {
            Console.WriteLine("[AVISO] Nenhuma amostra de treinamento fornecida para esta √©poca.");
        }

        // Loop de treinamento sobre a lista em mem√≥ria
        for (int i = 0; i < trainingSamples.Count; i += batchSize)
        {
            var batch = trainingSamples.Skip(i).Take(batchSize).ToList();
            if (batch.Count == 0) break;

            var sequenceInputIndices = batch.Select(p => p.InputIndex).ToArray();
            var sequenceTargetIndices = batch.Select(p => p.TargetIndex).ToArray();

            model.ResetHiddenState();
            totalEpochLoss += model.TrainSequence(sequenceInputIndices, sequenceTargetIndices, learningRate);
            batchCount++;
            Console.Write($"\r  Lotes de treinamento processados: {batchCount} de {Math.Ceiling((double)trainingSamples.Count / batchSize)}...");

            model._cacheManager?.Reset();
        }

        _stopwatch.Stop();
        double avgLoss = batchCount > 0 ? totalEpochLoss / batchCount : double.PositiveInfinity;
        string elapsedFormatted = string.Format("{0:D2}:{1:D2}:{2:D2}", _stopwatch.Elapsed.Hours, _stopwatch.Elapsed.Minutes, _stopwatch.Elapsed.Seconds);
        
        Console.WriteLine($"\n√âpoca SFT conclu√≠da. Perda m√©dia: {avgLoss:F4} | Dura√ß√£o: {elapsedFormatted}");
        File.AppendAllText(logPath, $"√âpoca SFT conclu√≠da. Perda: {avgLoss}. Dura√ß√£o: {elapsedFormatted}{Environment.NewLine}");

        // Valida√ß√£o
        double validationLoss = ValidateModel(model, validationSamples, batchSize);
        Console.WriteLine($"Perda M√©dia de Valida√ß√£o: {validationLoss:F4}");
        File.AppendAllText(logPath, $"Perda M√©dia de Valida√ß√£o: {validationLoss:F4}{Environment.NewLine}");
    }

    private double ValidateModel(GenerativeNeuralNetworkLSTM modelToValidate, List<(int InputIndex, int TargetIndex)> validationSamples, int batchSize)
    {
        Console.WriteLine("\n[Valida√ß√£o] Iniciando...");
        double totalLoss = 0;
        int batchCount = 0;
        var validationStopwatch = Stopwatch.StartNew();
        
        if (validationSamples.Count == 0)
        {
            Console.WriteLine("[AVISO] Nenhuma amostra de valida√ß√£o fornecida.");
        }

        for (int i = 0; i < validationSamples.Count; i += batchSize)
        {
            var batch = validationSamples.Skip(i).Take(batchSize).ToList();
            if (batch.Count == 0) break;

            var sequenceInputIndices = batch.Select(p => p.InputIndex).ToArray();
            var sequenceTargetIndices = batch.Select(p => p.TargetIndex).ToArray();

            totalLoss += modelToValidate.CalculateSequenceLoss(sequenceInputIndices, sequenceTargetIndices);
            batchCount++;
            Console.Write($"\r[Valida√ß√£o] Processando lote de valida√ß√£o {batchCount}...");
            
            modelToValidate._cacheManager?.Reset();
        }

        validationStopwatch.Stop();
        _currentProcess.Refresh();
        long currentMemory = _currentProcess.WorkingSet64 / (1024 * 1024);
        Console.WriteLine($"\r[Valida√ß√£o] Conclu√≠da em {validationStopwatch.Elapsed:mm\\:ss}. | RAM: {currentMemory}MB");
        
        return batchCount > 0 ? totalLoss / batchCount : double.PositiveInfinity;
    }
}